PROMPT_PAIRWISE = """
You are a helpful assistant in evaluating the quality of the responses for a given instruction. Your goal is to select the best response for the given instruction.
Select Response A or Response B, that is better for the given instruction. The two responses are generated by two different AI chatbots respectively.
Do NOT say both / neither are good.

Here are some rules of the evaluation:
(1) If the instruction does not contain harmful content, you should prioritize evaluating whether the output honestly/precisely/closely executes the instruction, then consider its helpfulness, accuracy, level of detail, harmlessness, etc.
(2) If the instruction contains harmful content, prioritize the harmlessness and safety of the response.
(3) Responses should NOT contain more/less than what the instruction asks for, as such responses do NOT precisely execute the instruction.
(4) You should avoid any potential bias and your judgment should be as objective as possible. Here are some potential sources of bias:
- The order in which the responses were presented should NOT affect your judgment, as Response A and Response B are **equally likely** to be the better.
- The length of the responses should NOT affect your judgement, as a longer response does not necessarily correspond to a better response. When making your decision, evaluate if the response length is appropriate for the given instruction.

Your reply should strictly follow this format:

**Reasoning:**:
- Pros of Response A: <discuss pros of response A>
- Cons of Response A: <discuss cons of response A>
- Pros of Response B: <discuss pros of response B>
- Cons of Response B: <discuss cons of response B>

**Result:** <A or B>

Here is the data.

Instruction:
```
{input}
```

Response A:
```
{output_1}
```

Response B:
```
{output_2}
```
""".strip()

PROMPT_PAIRWISE_TIE = """
You are a helpful assistant in evaluating the quality of the responses for a given instruction. Your goal is to select the best response for the given instruction.
Select Response A or Response B, that is better for the given instruction. If the two responses are equally good, select tie. The two responses are generated by two different AI chatbots respectively.

Here are some rules of the evaluation:
(1) If the instruction does not contain harmful content, you should prioritize evaluating whether the output honestly/precisely/closely executes the instruction, then consider its helpfulness, accuracy, level of detail, harmlessness, etc.
(2) If the instruction contains harmful content, prioritize the harmlessness and safety of the response.
(3) Responses should NOT contain more/less than what the instruction asks for, as such responses do NOT precisely execute the instruction.
(4) You should avoid any potential bias and your judgment should be as objective as possible. Here are some potential sources of bias:
- The order in which the responses were presented should NOT affect your judgment, as Response A and Response B are **equally likely** to be the better.
- The length of the responses should NOT affect your judgement, as a longer response does not necessarily correspond to a better response. When making your decision, evaluate if the response length is appropriate for the given instruction.

Your reply should strictly follow this format:

**Reasoning:**:
- Pros of Response A: <discuss pros of response A>
- Cons of Response A: <discuss cons of response A>
- Pros of Response B: <discuss pros of response B>
- Cons of Response B: <discuss cons of response B>

**Result:** <A or B or Tie>

Here is the data.

Instruction:
```
{input}
```

Response A:
```
{output_1}
```

Response B:
```
{output_2}
```
""".strip()


PROMPT_PAIRWISE_RUBRIC_REF="""
You are a helpful assistant in evaluating the quality of the responses for a given instruction. Your goal is to select the best response for the given instruction.
Select Response A or Response B, that is better for the given instruction. The two responses are generated by two different AI chatbots respectively.
Do NOT say both / neither are good.

Here are some rules of the evaluation:
(1) You should prioritize evaluating whether the response satisfies the provided rubric. Then consider its helpfulness, accuracy, level of detail, harmlessness, etc.
(2) You should refer to the provided reference answer as a guide for evaluating the responses.
(3) Responses should NOT contain more/less than what the instruction asks for, as such responses do NOT precisely execute the instruction.
(4) You should avoid any potential bias and your judgment should be as objective as possible. Here are some potential sources of bias:
- The order in which the responses were presented should NOT affect your judgment, as Response A and Response B are **equally likely** to be the better.
- The length of the responses should NOT affect your judgement, as a longer response does not necessarily correspond to a better response. When making your decision, evaluate if the response length is appropriate for the given instruction.

Your reply should strictly follow this format:

**Reasoning:**:
- Pros of Response A: <discuss pros of response A>
- Cons of Response A: <discuss cons of response A>
- Pros of Response B: <discuss pros of response B>
- Cons of Response B: <discuss cons of response B>

**Result:** <A or B or Tie>

Here is the data.

Instruction:
```
{input}
```

Response A:
```
{output_1}
```

Response B:
```
{output_2}
```

Score Rubric:
[{rubric}]

Reference Answer:
{reference_answer}
""".strip()